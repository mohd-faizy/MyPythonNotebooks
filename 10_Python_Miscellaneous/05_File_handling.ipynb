{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["C04HUV6_zA85","rBMnjMn39VUY","MECUnd3j9e1D"],"toc_visible":true,"authorship_tag":"ABX9TyPEvLuxZox+9FUztAnWNahU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![link text](https://www.mytechmint.com/wp-content/uploads/2021/10/file-handling-in-python-mytechmint-720x340.jpg)"],"metadata":{"id":"WiPxLmVtzEuI"}},{"cell_type":"markdown","source":["# **Basic Concepts**"],"metadata":{"id":"C04HUV6_zA85"}},{"cell_type":"markdown","source":["\n","\n","\n","In Python, files can be handled using the `open()` function, which opens a file and returns a file object. The syntax is:\n","\n","```python\n","file = open(\"filename\", \"mode\")\n","```\n","\n","- `filename`: the name (and path, if necessary) of the file to open.\n","- `mode`: specifies how the file will be opened.\n","\n","### Common File Modes\n","\n","Let's look at the modes you'll use in file handling with Python:\n","\n","1. `\"r\"` (Read)` - Opens a file for reading (default mode).\n","2. `\"rb\"` (Read Binary) - Opens a file for reading in binary mode.\n","3. `\"w\"` (Write) - Opens a file for writing. Creates a new file if it doesn't exist or truncates the file if it exists.\n","4. `\"wb\"` (Write Binary) - Opens a file for writing in binary mode.\n","5. `\"a\"` (Append) - Opens a file for appending. Data is added to the end of the file if it exists, or a new file is created if it doesn't.\n","6. `\"r+\"` (Read and Write) - Opens a file for both reading and writing. The file pointer is placed at the beginning of the file.\n","7. `\"w+\"` (Write and Read) - Opens a file for both writing and reading. Creates a new file if it doesnâ€™t exist or truncates the file if it does.\n","8. `\"a+\"` (Append and Read) - Opens a file for both appending and reading."],"metadata":{"id":"gE-06ZCiwxxE"}},{"cell_type":"markdown","source":["### 1. Read Mode (\"r\")"],"metadata":{"id":"fiMivKJGxkoY"}},{"cell_type":"code","source":["# Create a sample file\n","with open(\"/content/sample.txt\", \"w\") as file:\n","    file.write(\"Hello, this is a sample text file.\\nWelcome to file handling in Python!\")\n","\n","# Reading a file in \"r\" mode\n","try:\n","    with open(\"/content/sample.txt\", \"r\") as file:\n","        content = file.read()\n","        print(\"Content of the file in 'r' mode:\")\n","        print(content)\n","except FileNotFoundError:\n","    print(\"File not found!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ahQX9oZxdzI","executionInfo":{"status":"ok","timestamp":1730032813586,"user_tz":-330,"elapsed":17,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"d00be952-c74f-45ba-9757-77560ed5c7bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Content of the file in 'r' mode:\n","Hello, this is a sample text file.\n","Welcome to file handling in Python!\n"]}]},{"cell_type":"markdown","source":["### 2. Read Binary Mode (\"rb\")"],"metadata":{"id":"n3ACK2RNxwNK"}},{"cell_type":"code","source":["# Reading a file in \"rb\" mode\n","try:\n","    with open(\"/content/sample.txt\", \"rb\") as file:\n","        content = file.read()\n","        print(\"Content of the file in 'rb' mode:\")\n","        print(content)\n","except FileNotFoundError:\n","    print(\"File not found!\")\n"],"metadata":{"id":"UfuJhwvcxs_w","executionInfo":{"status":"ok","timestamp":1730032813587,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"3eedc67d-fa68-4220-c8dc-a9dfa75eb8bb","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Content of the file in 'rb' mode:\n","b'Hello, this is a sample text file.\\nWelcome to file handling in Python!'\n"]}]},{"cell_type":"markdown","source":["### 3. Write Mode (\"w\")"],"metadata":{"id":"j8iNWhs2xyOR"}},{"cell_type":"code","source":["# Writing to a file in \"w\" mode (overwrites if file exists)\n","with open(\"/content/sample_write.txt\", \"w\") as file:\n","    file.write(\"This is a new file, created using 'w' mode.\")\n","\n","# Checking content\n","with open(\"/content/sample_write.txt\", \"r\") as file:\n","    print(\"Content of the file after 'w' mode write:\")\n","    print(file.read())\n"],"metadata":{"id":"qyxT8pkMxt3v","executionInfo":{"status":"ok","timestamp":1730032813587,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"64d0f81e-7f53-4eb7-9490-a3c5066e4121","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Content of the file after 'w' mode write:\n","This is a new file, created using 'w' mode.\n"]}]},{"cell_type":"markdown","source":["### 4. Write Binary Mode (\"wb\")"],"metadata":{"id":"8B8cPnTRxzW4"}},{"cell_type":"code","source":["# Writing to a file in binary mode \"wb\"\n","data = \"Binary data example\".encode(\"utf-8\")  # Encoding string to bytes\n","with open(\"/content/sample_binary.bin\", \"wb\") as file:\n","    file.write(data)\n","\n","# Reading the binary content back\n","with open(\"/content/sample_binary.bin\", \"rb\") as file:\n","    content = file.read()\n","    print(\"Binary content of the file written with 'wb' mode:\")\n","    print(content)"],"metadata":{"id":"HVD6wibjx11p","executionInfo":{"status":"ok","timestamp":1730032813587,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"5a711438-b1a9-49a3-dce2-f39891f013ab","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Binary content of the file written with 'wb' mode:\n","b'Binary data example'\n"]}]},{"cell_type":"markdown","source":["### 5. Append Mode (\"a\")"],"metadata":{"id":"v7Oip5Xtx24Q"}},{"cell_type":"code","source":["# Appending to an existing file with \"a\" mode\n","with open(\"/content/sample_write.txt\", \"a\") as file:\n","    file.write(\"\\nThis line is added using append mode.\")\n","\n","# Reading content to confirm append\n","with open(\"/content/sample_write.txt\", \"r\") as file:\n","    print(\"Content after appending in 'a' mode:\")\n","    print(file.read())"],"metadata":{"id":"HYh-fBmEyBOI","executionInfo":{"status":"ok","timestamp":1730032813587,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"acd3610b-19d4-4988-cb6e-292396e2ffa2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Content after appending in 'a' mode:\n","This is a new file, created using 'w' mode.\n","This line is added using append mode.\n"]}]},{"cell_type":"markdown","source":["### 6. Read and Write Mode (\"r+\")"],"metadata":{"id":"DSmjO-vDx5uC"}},{"cell_type":"code","source":["# Read and write in \"r+\" mode\n","with open(\"/content/sample_write.txt\", \"r+\") as file:\n","    content = file.read()\n","    print(\"Original Content in 'r+' mode:\", content)\n","    file.write(\"\\nAdding this line with 'r+' mode.\")\n","\n","# Verify content\n","with open(\"/content/sample_write.txt\", \"r\") as file:\n","    print(\"Content after 'r+' mode operation:\")\n","    print(file.read())"],"metadata":{"id":"_L0-letEyBkQ","executionInfo":{"status":"ok","timestamp":1730032813587,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"c71dabe9-d287-4928-8c28-0c9ebe8ee1d7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Content in 'r+' mode: This is a new file, created using 'w' mode.\n","This line is added using append mode.\n","Content after 'r+' mode operation:\n","This is a new file, created using 'w' mode.\n","This line is added using append mode.\n","Adding this line with 'r+' mode.\n"]}]},{"cell_type":"markdown","source":["### 7. Write and Read Mode (\"w+\")"],"metadata":{"id":"K71pe5nMx7_I"}},{"cell_type":"code","source":["# Write and read in \"w+\" mode\n","with open(\"/content/sample_w_plus.txt\", \"w+\") as file:\n","    file.write(\"This file is created with 'w+' mode.\")\n","    file.seek(0)  # Move pointer to beginning of file to read\n","    print(\"Content written and read in 'w+' mode:\")\n","    print(file.read())"],"metadata":{"id":"8buskgabyB7o","executionInfo":{"status":"ok","timestamp":1730032813588,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"d2df2232-5dc1-48da-cd48-ce7cb77aa8c3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Content written and read in 'w+' mode:\n","This file is created with 'w+' mode.\n"]}]},{"cell_type":"markdown","source":["### 8. Append and Read Mode (\"a+\")"],"metadata":{"id":"wCmjDIX9x9lp"}},{"cell_type":"code","source":["# Append and read in \"a+\" mode\n","with open(\"/content/sample_write.txt\", \"a+\") as file:\n","    file.write(\"\\nAppended with 'a+' mode.\")\n","    file.seek(0)  # Move pointer to beginning of file to read all content\n","    print(\"Content after 'a+' mode operation:\")\n","    print(file.read())"],"metadata":{"id":"kCQWjgpmyCeJ","executionInfo":{"status":"ok","timestamp":1730032813588,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"9cf98f11-986d-4c66-a51f-b6e5c17582ae","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Content after 'a+' mode operation:\n","This is a new file, created using 'w' mode.\n","This line is added using append mode.\n","Adding this line with 'r+' mode.\n","Appended with 'a+' mode.\n"]}]},{"cell_type":"markdown","source":["### Summary Table\n","\n","| Mode | Description |\n","| --- | --- |\n","| \"r\" | Read-only, file must exist |\n","| \"rb\" | Read-only in binary mode, file must exist |\n","| \"w\" | Write-only, creates/truncates |\n","| \"wb\" | Write-only in binary mode, creates/truncates |\n","| \"a\" | Append-only, creates if not exists |\n","| \"r+\" | Read and write, file must exist |\n","| \"w+\" | Write and read, creates/truncates |\n","| \"a+\" | Append and read, creates if not exists |"],"metadata":{"id":"_gEROYv4yzcQ"}},{"cell_type":"markdown","source":["# **Advanced File Handling Concepts in AI and NLP**"],"metadata":{"id":"UW-5gaymzV8f"}},{"cell_type":"markdown","source":["**Common File Types in AI and NLP**\n","\n","1. **Text Files (\"`.txt`\")**: Commonly used for storing raw text data.\n","2. **CSV Files (\"`.csv`\")**: Used for structured datasets in tabular format.\n","3. **JSON Files (\"`.json`\")**: Popular for hierarchical data structures, used in many NLP datasets.\n","4. **Binary Files (e.g., \"`.pkl`\" for Pickle)**: Useful for saving preprocessed data, models, and embeddings efficiently."],"metadata":{"id":"zSyleN9Uzd54"}},{"cell_type":"markdown","source":["### **1. Reading Large Text Files Line-by-Line (Streaming Data)**\n","\n","For massive text corpora, line-by-line reading avoids loading the entire file into memory."],"metadata":{"id":"Y03Mvv1665bo"}},{"cell_type":"code","source":["import os\n","\n","# Function to check for the file and create a dummy if not found\n","def process_large_text_file(file_path):\n","    # Check if file exists\n","    if not os.path.exists(file_path):\n","        # Create a dummy file if it doesn't exist\n","        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","            file.write(\"This is a sample line in the dummy file.\\nAnother sample line.\\n\")\n","        print(f\"Dummy file created at: {file_path}\")\n","\n","    # Processing large text file line-by-line\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        for line in file:\n","            # Simulate tokenizing the line\n","            tokens = line.strip().split()\n","            # Process tokens (e.g., store or use in model pipeline)\n","            print(tokens[:5])  # Displaying first 5 tokens as an example\n","\n","# Test the function\n","process_large_text_file(\"/content/large_text_corpus.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5jkdpQH-Vtc","executionInfo":{"status":"ok","timestamp":1730032813588,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"95060fe1-0b93-43a4-c1c1-9357eaf54692"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['This', 'is', 'a', 'sample', 'line']\n","['Another', 'sample', 'line.']\n"]}]},{"cell_type":"markdown","source":["This approach is memory efficient and ideal for tokenizing or embedding large datasets."],"metadata":{"id":"uKtgYhjf8znE"}},{"cell_type":"markdown","source":["### **2. Working with JSON Files for Dataset Structures**\n","\n","Many NLP datasets, such as those from Hugging Faceâ€™s datasets library, are stored in JSON format, where each line represents a document or data entry"],"metadata":{"id":"_XCyYo5Q873N"}},{"cell_type":"code","source":["import os\n","import json\n","\n","# Function to check for the file and create a dummy JSON file if not found\n","def load_json_dataset(file_path):\n","    # Check if file exists\n","    if not os.path.exists(file_path):\n","        # Create a dummy JSON file with sample data if it doesn't exist\n","        sample_data = [\n","            {\"text\": \"This is a sample entry 1\", \"label\": \"example\"},\n","            {\"text\": \"This is a sample entry 2\", \"label\": \"example\"}\n","        ]\n","        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","            for entry in sample_data:\n","                json.dump(entry, file)\n","                file.write(\"\\n\")\n","        print(f\"Dummy JSON file created at: {file_path}\")\n","\n","    # Reading JSON file with NLP data\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        data = [json.loads(line) for line in file]\n","    return data\n","\n","# Test the function\n","dataset = load_json_dataset(\"/content/nlp_dataset.json\")\n","print(\"First entry:\", dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Pmx2RHJ-qL5","executionInfo":{"status":"ok","timestamp":1730032813588,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"ab382c5c-299e-47bb-cf72-9320c41784b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First entry: {'text': 'This is a sample entry 1', 'label': 'example'}\n"]}]},{"cell_type":"markdown","source":["### **3. Writing Model Outputs and Metadata in JSON Format**\n","\n","After processing text data, you may need to save outputs or metadata. Writing to JSON allows flexible storage of structured data."],"metadata":{"id":"eI7Lxfou9Dfj"}},{"cell_type":"code","source":["import json\n","\n","# Reading JSON file with NLP data\n","def load_json_dataset(file_path):\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        data = [json.loads(line) for line in file]\n","    return data\n","\n","dataset = load_json_dataset(\"/content/nlp_dataset.json\")\n","print(\"First entry:\", dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lS1vmrY9LAR","executionInfo":{"status":"ok","timestamp":1730032813589,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"2cfe9a77-4c0d-478b-d047-4b6279904f2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First entry: {'text': 'This is a sample entry 1', 'label': 'example'}\n"]}]},{"cell_type":"markdown","source":["### **4. Working with CSV Files for Structured Tabular Data**\n","\n","CSV files are ideal for tabular data often found in NLP tasks, like classification labels or sentence pairs."],"metadata":{"id":"0yhzTHAp9QMC"}},{"cell_type":"code","source":["import os\n","import csv\n","\n","# Function to check for the file and create a dummy CSV if not found\n","def load_csv_dataset(file_path):\n","    # Check if file exists\n","    if not os.path.exists(file_path):\n","        # Create a dummy CSV file with sample data if it doesn't exist\n","        with open(file_path, mode=\"w\", encoding=\"utf-8\", newline='') as file:\n","            writer = csv.DictWriter(file, fieldnames=[\"text\", \"label\"])\n","            writer.writeheader()  # Write the header\n","            writer.writerow({\"text\": \"This is a sample text 1\", \"label\": \"example\"})\n","            writer.writerow({\"text\": \"This is a sample text 2\", \"label\": \"example\"})\n","        print(f\"Dummy CSV file created at: {file_path}\")\n","\n","    # Proceed with loading the CSV data\n","    with open(file_path, mode=\"r\", encoding=\"utf-8\") as file:\n","        reader = csv.DictReader(file)\n","        data = [row for row in reader]\n","    return data\n","\n","# Test the function\n","csv_data = load_csv_dataset(\"/content/classification_data.csv\")\n","print(\"First row:\", csv_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWlzOjEY9TSw","executionInfo":{"status":"ok","timestamp":1730032813589,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"770630ce-c501-404c-9ce5-cff1ae97dfc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First row: {'text': 'This is a sample text 1', 'label': 'example'}\n"]}]},{"cell_type":"markdown","source":["### **5. Handling Binary Files for Preprocessed Data and Embeddings**\n","\n","Binary files are frequently used to save preprocessed data (like tokenized inputs) and embeddings. The `pickle` library is useful here for serialization."],"metadata":{"id":"rBMnjMn39VUY"}},{"cell_type":"code","source":["import os\n","import pickle\n","\n","# Saving and loading preprocessed embeddings\n","def save_embeddings(data, file_path):\n","    with open(file_path, \"wb\") as file:\n","        pickle.dump(data, file)\n","\n","def load_embeddings(file_path):\n","    # Check if file exists\n","    if not os.path.exists(file_path):\n","        # Create a dummy pickle file with sample embeddings if it doesn't exist\n","        dummy_data = {\"example_word\": [0.0, 0.1, 0.2]}\n","        with open(file_path, \"wb\") as file:\n","            pickle.dump(dummy_data, file)\n","        print(f\"Dummy pickle file created at: {file_path}\")\n","\n","    # Proceed with loading the embeddings\n","    with open(file_path, \"rb\") as file:\n","        data = pickle.load(file)\n","    return data\n","\n","# Example usage\n","sample_embeddings = {\"word\": [0.1, 0.2, 0.3]}\n","save_embeddings(sample_embeddings, \"/content/embeddings.pkl\")\n","loaded_embeddings = load_embeddings(\"/content/embeddings.pkl\")\n","print(\"Loaded embeddings:\", loaded_embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gghg0UqB9bt6","executionInfo":{"status":"ok","timestamp":1730032813589,"user_tz":-330,"elapsed":11,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"428c05f2-924e-45eb-e46c-5b510a985a18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded embeddings: {'word': [0.1, 0.2, 0.3]}\n"]}]},{"cell_type":"markdown","source":["### **6. File Management for Model Checkpoints and Artifacts**\n","\n","For larger AI workflows, managing checkpoints and output files is critical. This can be automated using file handling with os and shutil libraries."],"metadata":{"id":"MECUnd3j9e1D"}},{"cell_type":"code","source":["import os\n","import shutil\n","import pickle\n","\n","# Saving a model checkpoint\n","def save_checkpoint(checkpoint, directory=\"checkpoints\", filename=\"model.ckpt\"):\n","    # Ensure the directory exists\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","    path = os.path.join(directory, filename)\n","    # Save the checkpoint\n","    with open(path, \"wb\") as file:\n","        pickle.dump(checkpoint, file)\n","\n","# Loading the checkpoint\n","def load_checkpoint(directory=\"checkpoints\", filename=\"model.ckpt\"):\n","    path = os.path.join(directory, filename)\n","    # Check if the checkpoint file exists\n","    if not os.path.exists(path):\n","        # Create a dummy checkpoint file with sample data if it doesn't exist\n","        dummy_checkpoint = {\"epoch\": 0, \"accuracy\": 0.0}\n","        save_checkpoint(dummy_checkpoint, directory, filename)\n","        print(f\"Dummy checkpoint created at: {path}\")\n","\n","    # Load the checkpoint\n","    with open(path, \"rb\") as file:\n","        checkpoint = pickle.load(file)\n","    return checkpoint\n","\n","# Example checkpoint data\n","checkpoint_data = {\"epoch\": 10, \"accuracy\": 0.85}\n","save_checkpoint(checkpoint_data)\n","loaded_checkpoint = load_checkpoint()\n","print(\"Loaded checkpoint:\", loaded_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqQnYiFD9kQR","executionInfo":{"status":"ok","timestamp":1730032813589,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"24af78ac-b900-45b2-d13d-d4afe087b5d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded checkpoint: {'epoch': 10, 'accuracy': 0.85}\n"]}]},{"cell_type":"markdown","source":["### Summary of Advanced File Handling Techniques\n","\n","| Mode/Technique | Description |\n","| --- | --- |\n","| **Line-by-line reading** | Efficient reading for large corpora without memory overload. |\n","| **JSON handling** | Structured data format commonly used in NLP datasets. |\n","| **CSV handling** | Useful for tabular data like classification labels or token metadata. |\n","| **Binary (Pickle)** | Fast serialization for saving model weights, embeddings, and checkpoints. |\n","| **File management** | Using `os` and `shutil` for organizing checkpoints and outputs in larger AI workflows. |"],"metadata":{"id":"RlHbV_co9nep"}},{"cell_type":"code","source":["pip install yfinance pandas numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xu5PQ-hI9npB","executionInfo":{"status":"ok","timestamp":1730149815422,"user_tz":-330,"elapsed":12364,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"4256e946-e4d7-4ab8-bd35-100801eb2a8b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.46)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n","Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.7)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import yfinance as yf\n","import pandas as pd\n","import numpy as np\n","\n","# Parameters for the moving average strategy\n","SHORT_WINDOW = 40  # Short moving average period\n","LONG_WINDOW = 100  # Long moving average period\n","INITIAL_CAPITAL = 10000  # Starting capital in dollars\n","\n","# Fetch stock data\n","def fetch_data(ticker, start_date, end_date):\n","    data = yf.download(ticker, start=start_date, end=end_date)\n","    data['Short_MA'] = data['Close'].rolling(window=SHORT_WINDOW, min_periods=1).mean()\n","    data['Long_MA'] = data['Close'].rolling(window=LONG_WINDOW, min_periods=1).mean()\n","    return data\n","\n","# Generate trading signals\n","def generate_signals(data):\n","    data['Signal'] = 0.0\n","    data['Signal'][SHORT_WINDOW:] = np.where(data['Short_MA'][SHORT_WINDOW:] > data['Long_MA'][SHORT_WINDOW:], 1.0, 0.0)\n","    data['Position'] = data['Signal'].diff()\n","    return data\n","\n","# Simulate trading with the strategy\n","def simulate_trading(data):\n","    positions = INITIAL_CAPITAL / data['Close'][0]\n","    cash = INITIAL_CAPITAL\n","    holdings = 0\n","\n","    for index, row in data.iterrows():\n","        if row['Position'] == 1:  # Buy signal\n","            holdings = cash / row['Close']\n","            cash = 0\n","            print(f\"Buy {row['Close']} on {index}\")\n","        elif row['Position'] == -1:  # Sell signal\n","            cash = holdings * row['Close']\n","            holdings = 0\n","            print(f\"Sell {row['Close']} on {index}\")\n","\n","    final_value = cash + (holdings * data['Close'].iloc[-1])\n","    print(f\"Final Portfolio Value: ${final_value:.2f}\")\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    ticker = \"AAPL\"  # Apple stock for example\n","    start_date = \"2020-01-01\"\n","    end_date = \"2023-01-01\"\n","\n","    data = fetch_data(ticker, start_date, end_date)\n","    data = generate_signals(data)\n","    simulate_trading(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"cSej0W3Y9p_L","executionInfo":{"status":"error","timestamp":1730149819155,"user_tz":-330,"elapsed":3739,"user":{"displayName":"Mohd Faizy","userId":"00466318749872658969"}},"outputId":"d7a07a33-a220-441a-fa42-478a4b8bd150"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n","<ipython-input-2-9ec6dc2fa3ec>:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Signal'][SHORT_WINDOW:] = np.where(data['Short_MA'][SHORT_WINDOW:] > data['Long_MA'][SHORT_WINDOW:], 1.0, 0.0)\n"]},{"output_type":"error","ename":"KeyError","evalue":"0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9ec6dc2fa3ec>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0msimulate_trading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-9ec6dc2fa3ec>\u001b[0m in \u001b[0;36msimulate_trading\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Simulate trading with the strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimulate_trading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINITIAL_CAPITAL\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mcash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINITIAL_CAPITAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mholdings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0"]}]}]}